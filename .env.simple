# .env

# --- REQUIRED ---
# Comma-separated list of API keys allowed to access the server
ALLOWED_API_KEYS="sk-local-key-dev,another-secret-key" # Replace with your actual desired keys

# --- OPTIONAL (defaults are in settings.py, but can be overridden here) ---
HOST="0.0.0.0"
PORT=11111
# LOG_LEVEL="INFO" # Set to DEBUG for more verbose logging if needed
# VERBOSE_LLAMA=False # Set to True for very detailed llama.cpp core logs (can be noisy)

# --- MODEL CONFIGURATION ---
# This is now primarily handled in config/settings.py's MODELS list.
# If you were to use MODELS_CONFIG environment variable, it would look like:
MODELS_CONFIG='[{"model_id": "gemma-3-4b", "model_path": "/app/models/gemma-3-4b-it-q4_0.gguf", "n_gpu_layers": -1, "is_multimodal": true}]'
# But since you're editing settings.py directly for the MODELS list, you might not need MODELS_CONFIG in .env.
